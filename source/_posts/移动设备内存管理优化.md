---
title: Android设备内存管理与应用保活机制探究
date: 2025-12-26 23:54
categories:
  - 操作系统
  - 计算机科学
tags:
  - 操作系统
  - Android
  - 内存
---



**背景**：用户每天应用切换超过100次，重启延迟是关键体验指标，厂商以"保活几十个APP"为卖点。实际上数据显示用户日均使用APP不超过7个，**核心体验重于保活数量**

基础内存回收策略：杀进程（进程终止，冷启动，用户体验差），换页到闪存（慢速IO），写入损耗闪存寿命（SWAP方案）

ZRAM：**在DRAM内部创建透明压缩的虚拟存储层，把数据压缩后**仍在内存里待着。LRU只认最近使用，但是有些数据是打开APP时必用的，ZRAM可能把这些热数据也压缩了，导致每次打开都解压，**明明不解压也能放得下**。

文章发现ZRAM技术有三大缺陷

- 未区分冷热数据
- 未适配压缩块大小
- 未利用数据局部性

这些缺陷导致了应用重启延迟增加并浪费CPU时间

针对ZRAM技术的不足，文章提出解决方案，即 Ariadne：

- 低开销的热感知数据组织机制
- 适配数据热度的自适应压缩块大小策略
- 基于访问预测的主动解压机制

设备：Google Pixel 7（Android 14）

实验结果：Ariadne平均降低50%应用重启延迟，减少15%压缩解压CPU开销

核心目标：**在最大限度保持后台应用存活的前提下，最小化应用重启延迟并降低CPU资源浪费**

Ariadne包含**三大关键技术**：

1. **低开销的热感知数据组织方案**：区分冷热数据，尽可能将热数据与压缩后的温数据保留在主存，仅将压缩后的冷数据交换至二级存储。
2. **尺寸自适应压缩方案**：对热数据和温数据采用小尺寸压缩以确保快速重启与执行；对冷数据采用大尺寸压缩以获得高压缩率。
3. **主动解压方案**：预测即将使用的数据集并提前解压，以降低数据换回主存及解压延迟对重启的负面影响。

然后文章介绍了 **ZRAM 工作流程：**

第一步：系统识别并移动一组**最近最少使用的数据页**到主机CPU或加速器进行压缩

第二步：系统将压缩后的数据块写回DRAM中的zpool区域

第三步：当用户启动应用，系统从zpool读取该应用相关的压缩数据块到主机CPU并进行解压。

第四步：系统将解压后的页面写回主存以支持应用A重启

第五步：系统合并未使用的压缩数据，将这个新块写回zpool。此过程涉及高成本的数据移动。

> 疑问：系统识别并移动一组最近最少使用的数据页到主机CPU或加速器进行压缩，“最近最少使用”指的是什么？
>
> 即LRU，基于**时间局部性**原理的预测算法，当需要腾出空闲内存时，优先选择**最久没有被访问过的页**作为“牺牲品”移出。
>
> 那么如何量化评估哪个页是最久没有访问过的
>
> 现代内核（包括Android）使用**双链LRU链表**来量化页面的“冷热”程度：
>
> - **活跃链表（Active List）** ：存放**最近被访问过**的页面。被认为是“热”数据。
> - **非活跃链表（Inactive List）** ：存放**近期未被访问**的页面。被认为是“冷”数据。
>
> 当一个页被访问（读/写）时，内核会将其标记并**移动到对应LRU链表的头部**。随着时间推移，未被再次访问的页会逐渐向链表尾部“沉淀”。
>
> MMU会维护一个**PG_referenced访问位，如果页面被硬件访问过，该位会被置位**
>
> 页面回收器扫描LRU链表时，会检查该位
>
> - 如果 `PG_referenced = 1`，说明这个“冷”页在放入非活跃链表后又被访问过，于是给它一次“机会”：清除该位，并将其**移回活跃链表的头部**，使其“复活”。
> - 如果 `PG_referenced = 0`，说明它在非活跃期间确实没有被访问过，则被判定为真正的“冷”页，成为压缩（或交换）的候选对象。

 



观察不同内存交换方案下的应用重启延迟。观察到ZRAM的表现优于基于闪存的SWAP方案。然而，由于压缩与解压操作带来的延迟，与应用数据直接从DRAM（无压缩/解压）读取相比，ZRAM平均仍会**使应用重启延迟增加2.1倍**。



上图展现了不同交换方案下内存回收过程（即kswapd线程）的CPU使用率，观察到ZRAM方案导致内存回收过程的CPU使用率平均**达到DRAM方案的2.6倍、SWAP方案的2.0倍**。



按压缩时间的顺序对所有压缩数据进行排序，然后将它们分成十个等大的部分。第0部分的数据是最先被压缩的。文章认为，**热数据出现在第零部分**是系统失效的关键标志（因为如果要最小化交换，冷数据应较早换出）

实验方法：

1. 首先将所有收集到的压缩数据块，按照它们**被压缩的时间戳**进行排序
2. 将排序后的数据序列均分为10份（Part 0 到 Part 9）。Part 0是最早被压缩的，Part 9是最后被压缩的。
3. 基于数据被压缩之前一段时间内的访问频率把数据分成热，温，冷数据

理想情况下，Part 0中应该是“冷”数据占绝对主导，Part 9中应该是“热”数据占绝对主导。但是这几个软件即使在Part 0也有大量热数据。这是因为LRU是一种**被动反应型**算法，只记录历史，不做预测。它无法知道用户**接下来最可能打开哪个应用**，或者一个后台应用**哪些数据正在被服务（如音乐播放、消息同步）**。这引发了频繁且不必要的解压操作，是造成**应用重启延迟高**和**CPU占用高**的根本原因。作者提出的Ariadne策略不再将内存压缩视为一个被动的、无差别的紧急救援手段，而是一种主动的，预测性的，分层的内存资源调度策略。

由这个实验，揭示了当前的ZRAM（使用LRU算法）在置换数据时**完全无法区分冷热数据，如果要设计一个能区别冷热数据的方法，就得找出热数据的规律和特征，文章接下来就对这个问题进行了研究（研究了同一应用在连续两次重启之间相同热数据的百分比）：研究发现同一应用连续两次重启间的平均热数据相似度为70%，平均数据复用率达到98%

这样就找到了热数据的规律：一次重启中的热数据极有可能在后续重启中再次成为热数据或温数据。

 



总结：

Ariadne 依据数据的热度等级动态调整压缩块尺寸，并基于数据访问的局部性特征实施前瞻性解压

> 什么是基于数据访问的局部性特征实施前瞻性解压？
>
> 程序在执行时，其访问的数据往往呈现出**聚集倾向**，而非完全随机。如果某个内存位置被访问，那么它**附近的位置**在不久的将来也很可能被访问。如果某个内存位置被访问，那么它**自身**在不久的将来很可能**再次**被访问。论文通过实测发现：当应用从ZRAM的`zpool`中读取压缩数据以完成重启时，**如果它当前正在访问第N个压缩块，那么接下来访问第N+1个块的概率非常高（例如，YouTube达86%）**。

 

综合文章，分析Ariadne把数据分成了哪三种，是如何划分的（根据什么划分的），为什么要这样划分

Ariadne将匿名内存数据分为热数据，温数据，冷数据，是动态的预测性的划分。系统为热、温、冷数据分别维护独立的LRU链表，实现物理和逻辑上的隔离管理。

该方法对数据的划分并非完全依赖历史，甚至还结合了**空间局部性预测**。比如当系统因空间局部性预取一个温数据页并命中后，会强化该页及其相邻页的“温”属性评估。